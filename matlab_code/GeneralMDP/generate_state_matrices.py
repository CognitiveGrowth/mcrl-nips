import sys
import numpy as np
import scipy.misc
import scipy.io
import matplotlib.pyplot as plt

def n_bib(balls,bins):
    return scipy.misc.comb(balls+bins-1,balls)

def n_st(n_balls,n_arms): #excluding terminal state
    return int(np.sum([n_bib(i,n_arms*2) for i in range(n_balls+1)]))

def check(T,b):
    a = np.where(np.all(T==b,axis=1))
    if len(a[0]) > 0:
        return a[0][0]
    else:
        return -1

def states(n_balls,n_arms,rewardCorrect=1.0,cost=-1,constantArm=-1):

    if cost == -1: # Set cost to horizon-bounding value by default
        cost = rewardCorrect/n_balls

    S = np.ones((1,n_arms*2)) # Matrix of all possible states

    n_states = n_st(n_balls,n_arms) # Number of all possible states
    T1 = np.zeros((n_states+1,n_states+1,n_arms)) # Transition tensor

    balls = 0 # Counter for which observation is happening
    ipb = 0 # Index of previous basis
    count_added = 0 # Number of states added with the current number of balls
    state_count = 0

    while balls < n_balls:
        for j in range(count_added+1): # Use each of the states added with balls-1 observations as bases
            for i in range(n_arms*2): # Distribute the ball to each bin
                new = S[ipb].copy() # Copy the previous basis

                # Get the probability of making this observation
                if i%2 == 0: #ON or OFF observation
                    p = new[i]/(new[i] + new[i+1])
                else:
                    p = new[i]/(new[i] + new[i-1])

                # Prepare and add the new state generated by the observation
                new[i] += 1
                k = check(S,new)

                if k == -1: #If it isn't already added
                    S = np.vstack((S,new))
                    count_added += 1
                    state_count += 1
                    T1[ipb,state_count,i//2] = p
                else:
                    T1[ipb,k,i//2] = p
            count_added -= 1 # Remove the added one to balance after the initial case
            ipb += 1 # Move down the previously added states at observation balls-1
        balls += 1

    S = np.vstack((S,-np.ones((1,n_arms*2)))) #Add the terminal state

    R = -cost*np.ones((n_states+1,n_arms+1))
    p = np.max([[s[2*j]/(s[2*j+1]+s[2*j]) for j in range(n_arms)] for s in S],1)
    R[:,-1] = rewardCorrect*p
    R[-1,:] = 0

    for i in range(n_states):
        if np.sum(S[i]) >= 2*n_arms+n_balls:
            T1[i,-1] = np.ones(n_arms)
            R[i,:] = R[i,-1]

    # The terminal state always goes back to itself
    t = np.zeros((n_states+1,n_arms))
    t[-1,:] = 1
    T1[-1] = t

    # Guessing action always leads to the terminal state
    T2 = np.zeros((n_states+1,n_states+1,1))
    T2[:,-1] = 1

    T = np.concatenate((T1,T2),axis=2)

    # Constant arm case
    if constantArm != -1:
        # Constant arm always leads to the terminal state
        T3 = np.zeros((n_states+1,n_states+1,1))
        T3[:,-1] = 1
        T = np.concatenate((T,T3),axis=2)

        #Constant arm has constant rewards
        Rc = constantArm*np.ones((n_states+1,1))
        Rc[-1] = 0
        R = np.concatenate((R,Rc),axis=1)

    return S,T,R

if __name__ == '__main__':
    n_balls=int(sys.argv[1])
    n_arms=int(sys.argv[2])
    rc=float(sys.argv[3])
    co=float(sys.argv[4])
    ca=float(sys.argv[5])
    print(n_balls,n_arms,rc,co,ca)
    print(n_st(n_balls,n_arms))
    s = states(n_balls,n_arms,rc,co,ca)
    a = {'states':s[0],'transition':s[1],'rewards':s[2]}
    scipy.io.savemat('./generalMDP/file',a)
